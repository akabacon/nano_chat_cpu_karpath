# NanoChat 快速上手指南 (Ubuntu 24.04)

本指南適用於 **Ubuntu 24.04** 環境，旨在提供一個最小化流程，讓你能在不依賴高階 GPU 的情況下，快速走通 NanoChat 的下載、安裝、Tokenizer 訓練、模型訓練與 Web 互動全流程。

---

## 🛠️ 第一階段：下載專案與環境配置

### 1. 複製 GitHub 儲存庫

首先，將專案下載到你的本地機器：

```bash
git clone https://github.com/karpathy/nanochat.git
cd nanochat

```

### 2. 建立虛擬環境

使用 Python 內建的 venv 建立隔離環境，並升級基礎工具：

```bash
python3 -m venv venv
source venv/bin/activate
pip install -U pip
# 先確保已經安裝
pip install pipreqs

# 使用 python 模組模式執行
python -m pipreqs.pipreqs .
pip install -r requirements.txt

```

### 3. 安裝 Rust 編譯環境

NanoChat 的 Tokenizer（`rustbpe`）需要 Rust 支援，請執行以下命令安裝：

```bash
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
source $HOME/.cargo/env

```

---

## 🧬 第二階段：Tokenizer 與模型訓練 (CPU 最小化測試)

此階段參數經過調整，適合在 CPU 上快速完成驗證。

### 1. 訓練 Tokenizer

訓練一個微型的 BPE 分詞器：

```bash
python -m scripts.tok_train --max_chars=100000

```

* **產出路徑**：`~/.cache/nanochat/tokenizer/`

### 2. 啟動最小化模型訓練

這將建立一個只有 2 層、序列長度為 64 的微型模型，僅需幾分鐘即可完成。

```bash
python -m scripts.base_train \
  --depth=2 \
  --max_seq_len=64 \
  --n_head=2 \
  --device_batch_size=1 \
  --total_batch_size=64 \
  --num_iterations=20 \
  --eval_tokens=128 \
  --core_metric_every=-1 \
  --sample_every=10

```

---

## 🌐 第三階段：檢查結果與 Web 互動

### 1. 檢查訓練產出

訓練完成後，請確認以下目錄已生成模型權重：

* **權重路徑**：`~/.cache/nanochat/base_checkpoints/d2/`
* **日誌確認**：終端機應顯示 `loss` 數值以及每 10 步生成的文本樣本。

### 2. 啟動聊天網頁界面

即使是最小化的模型，你也可以透過 Web UI 與它互動（雖然它的回答會是無意義的亂碼，但這證明了 Pipeline 已打通）：

```bash
python -m scripts.chat_web

```

* 啟動後，在瀏覽器打開：`http://127.0.0.1:5000`

---

## 💡 小撇步

* **資料儲存**：所有下載的數據與權重預設存放在 `~/.cache/nanochat`，若空間不足請留意。
* **效能調優**：如果你之後想切換回 GPU 訓練，只需確保 `torch.cuda.is_available()` 為 `True`，並增加 `--depth` (如 12) 與 `--max_seq_len` (如 1024)。

---

這份整合後的 Markdown 指南已經準備好了！需要我幫你將這段內容轉換成 `.sh` 自動化安裝腳本嗎？
